{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('/content/BankNifty Updated Data.csv')\n",
        "\n",
        "# Split the data into features and target\n",
        "X = data.drop(['Range'], axis=1)\n",
        "y = data['Range']\n",
        "\n",
        "# Convert date strings to datetime objects\n",
        "X['Date'] = pd.to_datetime(X['Date'])\n",
        "\n",
        "# Extract weekday and drop date column\n",
        "X['Day'] = X['Date'].dt.weekday\n",
        "X = X.drop('Date', axis=1)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Hyperparameter tuning for Gradient Boosting\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "rf_cv = GridSearchCV(rf, param_grid_rf, cv=5)\n",
        "rf_cv.fit(X_train, y_train)\n",
        "rf_best_params = rf_cv.best_params_\n",
        "\n",
        "# Hyperparameter tuning for Gradient Boosting\n",
        "gb = GradientBoostingRegressor(random_state=42)\n",
        "param_grid_gb = {\n",
        "    'n_estimators': [100, 200, 500],\n",
        "    'max_depth': [3, 5, 10],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "gb_cv = GridSearchCV(gb, param_grid_gb, cv=5)\n",
        "gb_cv.fit(X_train, y_train)\n",
        "gb_best_params = gb_cv.best_params_\n",
        "\n",
        "# Train the models with the best hyperparameters\n",
        "rf_model = RandomForestRegressor(random_state=42, **rf_best_params)\n",
        "gb_model = GradientBoostingRegressor(random_state=42, **gb_best_params)\n",
        "\n",
        "# Fit the models to the training data\n",
        "rf_model.fit(X_train, y_train)\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "rf_y_pred = rf_model.predict(X_test)\n",
        "gb_y_pred = gb_model.predict(X_test)\n",
        "\n",
        "# Ensemble the models using VotingRegressor\n",
        "ensemble_model = VotingRegressor([('rf', rf_model), ('gb', gb_model)])\n",
        "\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "# Make predictions on the test set using the ensemble model\n",
        "ensemble_model_y_pred = ensemble_model.predict(X_test)\n",
        "\n",
        "\n",
        "# Evaluate the performance of the models using mean squared error\n",
        "rf_mse = mean_squared_error(y_test, rf_y_pred)\n",
        "gb_mse = mean_squared_error(y_test, gb_y_pred)\n",
        "ensemble_mse = mean_squared_error(y_test, ensemble_model_y_pred)\n",
        "\n",
        "print(\"Random Forest Mean Squared Error:\", rf_mse)\n",
        "print(\"Gradient Boosting Mean Squared Error:\", gb_mse)\n",
        "print(\"Ensemble Mean Squared Error:\", ensemble_mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPgiDaOe0XjQ",
        "outputId": "d4ef4b29-36e9-4259-c348-f87d0c3fcaa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Mean Squared Error: 76235.36971047196\n",
            "Gradient Boosting Mean Squared Error: 65554.25929530173\n",
            "Ensemble Mean Squared Error: 69089.49989305991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the data for the next day\n",
        "next_day_data = pd.DataFrame({'Open': [42819.0], 'High': [43037.40] ,'Low': [42750.20] ,'Close': [43000.0], 'Shares Traded': [238716537],'Turnover (Rs. Cr)': [238716537],'Day': [4]})\n",
        "# Use the trained model to make a prediction for the next day's range\n",
        "next_day_range = ensemble_model.predict(next_day_data)\n",
        "\n",
        "# Print the predicted range for the next day\n",
        "print(\"Predicted range for next day (Friday):\", next_day_range[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQSzDc268sTU",
        "outputId": "4ba13f1c-7e6c-4c8b-9afd-01b346cb116b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted range for next day (Friday): 785.4836784064761\n"
          ]
        }
      ]
    }
  ]
}